{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1ba44d-e15c-4645-9cc2-f06f343e2986",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right; font-style: italic\">Lorenz Köhl\n",
    "<br>\n",
    "September 2022</div>\n",
    "\n",
    "# Reverse Dictionary\n",
    "\n",
    "Writing well is laborsome. A good dictionary helps but it's only usable in one direction.\n",
    "You have to think of a word, look it up, chase references and so on. Even more work!\n",
    "\n",
    "It may be helpful to look up words by meaning, by what we as writers want to express.\n",
    "For example, if we had a function `find_words(\"I'm lost for words\")`\n",
    "and it would present us with a choice of words:\n",
    "\n",
    "```\n",
    "astoundment, bewildered, blank, confus, distraught, perplexly, stagger, stound, unyielded\n",
    "```\n",
    "\n",
    "then we may find the right word we want, without all the gyrations of traditional dictionary use.\n",
    "\n",
    "Can we implement this function? The answer is yes and it's not hard (*if you know your way around python*)!\n",
    "\n",
    "*Dependencies for execution:*\n",
    "\n",
    "- an environment with the following and a computer with enough resources (ie. nvidia gpu and lots of RAM)\n",
    "- pytorch<br> `conda install pytorch torchvision torchaudio cudatoolkit=11.6 -c pytorch -c conda-forge`\n",
    "- [sentence-transformers](https://github.com/UKPLab/sentence-transformers):<br> `conda install -c conda-forge sentence-transformers`\n",
    "- [ScaNN](https://github.com/google-research/google-research/tree/master/scann):<br> `pip install scann`\n",
    "\n",
    "You'll also need a cleaned up version of the webster1913 dictionary\n",
    "[json file](https://www.dropbox.com/s/w62l6pdfl8dtw2z/webst.json?dl=0). \n",
    "Please find a cleaning script in the [repo](https://github.com/mye/simple-vector-search) which depends on\n",
    "[html5-parser](https://html5-parser.readthedocs.io/en/latest/):\n",
    "<br> \n",
    "`pip install --no-binary lxml html5-parser`\n",
    "\n",
    "`python cleanwebst.py <webst.json > cleanwebst.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b6932-1f7f-4522-8b7d-38a50b51dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a0d8746-6349-42fb-b441-8af257724dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f11f8-bff9-42a0-bb1e-4d2c3ecb18d2",
   "metadata": {},
   "source": [
    "We start of by loading the dictionary, embedding definitions into vectors (sentence embeddings) and indexing those vectors for approximate nearest neighbor search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b756745-62aa-45d1-891a-545b90def45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The brain and spinal cord; the cerebro-spinal axis; myelencephalon.',\n",
       " '[NL., from Gr. νεῦρον nerve.]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webst = json.load(open('cleanwebst.json'))\n",
    "webst['neuron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89c0be48-e783-4c0c-abb4-8201299e09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnet = SentenceTransformer('all-mpnet-base-v2') # could also use all-MiniLM-L6-v2 for lighter weight model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7273ff-4be4-4c7b-88cf-1e06ccedc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a while (about 30 minutes on my RTX 3060 TI)\n",
    "webst_embs = {word: mpnet.encode(defs) for word, defs in webst.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab4ad1f6-6dc8-4734-8358-38348714d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate([webst_embs[w] for w in webst_embs])\n",
    "dataset_words = np.array([w for w in webst_embs for e in webst_embs[w]])\n",
    "assert len(dataset) == len(dataset_words)\n",
    "np.save('embs.npy', dataset) # save data so we don't have to recompute when something bad happens\n",
    "np.save('words.npy', dataset_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32231b91-a06f-4cdc-b257-44b3142f4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_dataset = dataset / np.linalg.norm(dataset, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb1da317-0fe1-40a6-9cac-85808886a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = scann.scann_ops_pybind.builder(normalized_dataset, 10, \"dot_product\").tree(\n",
    "    num_leaves=2000, num_leaves_to_search=100, training_sample_size=250000).score_ah(\n",
    "    2, anisotropic_quantization_threshold=0.2).reorder(100).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4889292f-49d6-41e4-89f4-e88d93e5eb01",
   "metadata": {},
   "source": [
    "This did alot in a few cells, even if it doesn't look like much!\n",
    "We loaded a pretrained neural network and encoded the whole dictionary,\n",
    "which gives us around 270000 vector to search through.\n",
    "\n",
    "We now have everything to implement our word finding function.\n",
    "We simply encode the description (the meaning) into a vector and search for its neighbors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "701435b3-edd3-429f-8856-dd52e606dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(description: str):\n",
    "    emb = mpnet.encode(description)\n",
    "    neighbors, distances = searcher.search(emb, final_num_neighbors=10)\n",
    "    return set(dataset_words[neighbors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f10e036e-cd41-4f84-a2ff-17117aa98422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amazeful',\n",
       " 'astoundment',\n",
       " 'bewildered',\n",
       " 'blank',\n",
       " 'confus',\n",
       " 'distraught',\n",
       " 'perplexly',\n",
       " 'stagger',\n",
       " 'stound',\n",
       " 'unyielded'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_words(\"I'm lost for words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c7540-92f5-46e1-97ec-f729867a9202",
   "metadata": {},
   "source": [
    "Of course what we really want is more nicely formatted list with definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e44afc01-0d26-4abf-b5a3-7241a5972e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ed6974a4-4661-49ff-a30a-f9cfdb387aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_html(word, ndefs=5):\n",
    "    defs = [f'<i style=\"font-size: small\">{d}</i>' for d in webst[word][:ndefs]]\n",
    "    html = f'<li><b>{word}</b><br>{\"  //  \".join(defs)}</li>'\n",
    "    return html\n",
    "\n",
    "def display_words(desc):\n",
    "    words = find_words(desc)\n",
    "    htmls = [word_html(word) for word in words]\n",
    "    return HTML('<ul>' + \"\".join(htmls) + '</ul>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f653c710-d961-42d9-93cd-040be7f56c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul><li><b>confus</b><br><i style=\"font-size: small\">Confused, disturbed.</i>  //  <i style=\"font-size: small\">[F. See Confuse, adjective]</i></li><li><b>unyielded</b><br><i style=\"font-size: small\">To past particles, or to adjectives formed after the analogy of past particles, to indicate the absence of the condition or state expressed by them</i>  //  <i style=\"font-size: small\">See abased.</i>  //  <i style=\"font-size: small\">See abashed.</i>  //  <i style=\"font-size: small\">See abated.</i>  //  <i style=\"font-size: small\">See abolished.</i></li><li><b>blank</b><br><i style=\"font-size: small\">Of a white or pale color; without color.</i>  //  <i style=\"font-size: small\">Free from writing, printing, or marks; having an empty space to be filled in with some special writing; – said of checks, official documents, etc.; as, blank paper; a blank check; a blank ballot.</i>  //  <i style=\"font-size: small\">Utterly confounded or discomfited.</i>  //  <i style=\"font-size: small\">Empty; void; without result; fruitless; as, a blank space; a blank day.</i>  //  <i style=\"font-size: small\">Lacking characteristics which give variety; as, a blank desert; a blank wall; destitute of interests, affections, hopes, etc.; as, to live a blank existence; destitute of sensations; as, blank unconsciousness.</i></li><li><b>stound</b><br><i style=\"font-size: small\">To be in pain or sorrow.</i>  //  <i style=\"font-size: small\">Stunned.</i>  //  <i style=\"font-size: small\">A sudden, severe pain or grief; peril; alarm.</i>  //  <i style=\"font-size: small\">Astonishment; amazement.</i>  //  <i style=\"font-size: small\">Hour; time; season.</i></li><li><b>stagger</b><br><i style=\"font-size: small\">To move to one side and the other, as if about to fall, in standing or walking; not to stand or walk with steadiness; to sway; to reel or totter.</i>  //  <i style=\"font-size: small\">To cease to stand firm; to begin to give way; to fail.</i>  //  <i style=\"font-size: small\">To begin to doubt and waver in purpose; to become less confident or determined; to hesitate.</i>  //  <i style=\"font-size: small\">To cause to reel or totter.</i>  //  <i style=\"font-size: small\">To cause to doubt and waver; to make to hesitate; to make less steady or confident; to shock.</i></li><li><b>astoundment</b><br><i style=\"font-size: small\">Amazement.</i></li><li><b>bewildered</b><br><i style=\"font-size: small\">Greatly perplexed; as, a bewildered mind.</i></li><li><b>amazeful</b><br><i style=\"font-size: small\">Full of amazement.</i></li><li><b>perplexly</b><br><i style=\"font-size: small\">Perplexedly.</i></li><li><b>distraught</b><br><i style=\"font-size: small\">Torn asunder; separated.</i>  //  <i style=\"font-size: small\">Distracted; perplexed.</i>  //  <i style=\"font-size: small\">As if thou wert distraught and mad with terror. Shak.</i>  //  <i style=\"font-size: small\">To doubt betwixt our senses and our souls Which are the most distraught and full of pain. Mrs. Browning.</i>  //  <i style=\"font-size: small\">[OE. distract, distrauht. See Distract, adjective]</i></li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_words(\"I'm lost for words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5447062-3e92-4d0d-b9c8-eab48011dc68",
   "metadata": {},
   "source": [
    "That's a decent result for the wee bit of code we had to write.\n",
    "The quality of words isn't always perfect (false positives happen).\n",
    "Some words have a lot definitions and appear too often (eg. unyielded).\n",
    "We could for example think about how improve the embeddings,\n",
    "or we could increase the size of our dataset, and balance the number of\n",
    "definitions used for training. Then we could think about deploying it as a service to others.\n",
    "\n",
    "But before we do all that, let's gather some real world experience on how\n",
    "useful our model is in practice and get some writing done. Have fun!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
